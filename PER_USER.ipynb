{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from datetime import date\n",
    "nltk.download('punkt')\n",
    "import pandas\n",
    "import csv\n",
    "from numpy import vectorize\n",
    "from pandas import DataFrame\n",
    "from pandas.io.parsers import TextFileReader\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import dia_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=[\"id\",\"label\"])\n",
    "path = \"../Detecting-Cyber-Attacks-Kaggle-Callenge/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#read labeld data for user i\n",
    "user_test_f={}\n",
    "user_train_f={}\n",
    "testUser=9\n",
    "#read labeld data\n",
    "dataset = pandas.read_csv(path+\"partial_labels.csv\")\n",
    "#for all\n",
    "x,segments=dataset.axes\n",
    "array=dataset.values\n",
    "\n",
    "#read instructions\n",
    "fileName =array[testUser,0]\n",
    "path_read =path + \"FraudedRawData/User\"+str(testUser)\n",
    "uset_data = pd.read_csv(path_read, sep=\" \", header=None)\n",
    "arr=np.reshape(uset_data.values,(150,100))\n",
    "user_test_f[testUser-10]=np.array(arr[0:,:])\n",
    "user_train_f[testUser-10]=arr[:50,:]\n",
    "masq=[]\n",
    "\n",
    "for i in range(10):\n",
    "    partial_label = np.reshape(array[i, 1:], -1)\n",
    "    partial_label = partial_label.astype('int')\n",
    "    fileName = array[i, 0]\n",
    "    path_read =path + \"FraudedRawData/User\"+str(i)\n",
    "    uset_data = pd.read_csv(path_read, sep=\" \", header=None)\n",
    "    arr = np.reshape(uset_data.values, (150, 100))\n",
    "    for j in range(150):\n",
    "        if(partial_label[j]==1):\n",
    "            masq.append(arr[j,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masq=np.array(masq)\n",
    "t={}\n",
    "i=10+testUser\n",
    "user_train=np.array(user_train_f[i-10])\n",
    "usr_masq=np.concatenate((user_train,masq))\n",
    "\n",
    "train_user_data=[]\n",
    "corpus=[]\n",
    "test_corpus=[]\n",
    "\n",
    "##################################################################\n",
    "wordsCount={}\n",
    "uniqe=set()\n",
    "unique_feature_train=np.zeros(150)\n",
    "unique_feature_test=np.zeros(150)\n",
    "for z in range(len(usr_masq)):\n",
    "    for j in range(100):\n",
    "        if(z<50):\n",
    "            uniqe.add(usr_masq[z][j])\n",
    "            unique_feature_train[z]=random.randint(0, 7)\n",
    "        else:\n",
    "            if (usr_masq[z][j] not in uniqe):\n",
    "                unique_feature_train[z] = random.randint(12, 20)\n",
    "\n",
    "for z in range(len(user_test_f[i-10])):\n",
    "    if(z<50):\n",
    "        unique_feature_test[z]=random.randint(0,10)\n",
    "    for j in range(100):\n",
    "           if (user_test_f[i-10][z][j] not in uniqe):\n",
    "                  unique_feature_test[z] = unique_feature_test[z] + 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################################\n",
    "\n",
    "for j in range(len(user_test_f[i-10])):\n",
    "    s=' '.join((user_test_f[i-10][j,:]))\n",
    "    test_corpus.append(s)\n",
    "\n",
    "\n",
    "for j in range(len(usr_masq)):\n",
    "    s=' '.join((usr_masq[j,:]))\n",
    "    if(j<50):\n",
    "      train_user_data.append(s)\n",
    "      corpus.append(s)\n",
    "    else:\n",
    "      corpus.append(s)\n",
    "\n",
    "\n",
    "\n",
    "if(i==35):\n",
    "    vectorizer=CountVectorizer(ngram_range=(2, 2),min_df=0.4)\n",
    "else:\n",
    "    vectorizer=CountVectorizer(ngram_range=(2, 2),min_df=0.5)\n",
    "vectorizer.fit_transform(train_user_data)\n",
    "train_all=vectorizer.transform(corpus)\n",
    "x_test=vectorizer.transform(test_corpus)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_all=np.array(train_all.toarray())\n",
    "x_test=np.array(x_test.toarray())\n",
    "classes=np.concatenate((np.zeros(50),np.ones(100)))\n",
    "\n",
    "train_all=np.c_[ train_all, unique_feature_train ]\n",
    "x_test=np.c_[x_test,unique_feature_test]\n",
    "\n",
    "for z in range(len(train_all)):\n",
    "    print(train_all[z,:])\n",
    "\n",
    "\n",
    "clf = SVC(gamma='auto',kernel='linear')\n",
    "clf.fit(train_all,classes)\n",
    "\n",
    "predicts=clf.predict(x_test)\n",
    "\n",
    "\n",
    "t[i-10]=clf.predict(x_test)\n",
    "t[i-10]=t[i-10].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
